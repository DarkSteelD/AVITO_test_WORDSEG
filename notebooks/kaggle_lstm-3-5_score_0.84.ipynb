{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":13139048,"sourceType":"datasetVersion","datasetId":8324170}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q pytorch-crf\n\nimport pandas as pd\nimport numpy as np\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchcrf import CRF\nfrom sklearn.model_selection import train_test_split\nfrom tqdm.notebook import tqdm\nimport os\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Используется устройство: {device}\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-22T18:01:13.644894Z","iopub.execute_input":"2025-09-22T18:01:13.645191Z","iopub.status.idle":"2025-09-22T18:01:17.213411Z","shell.execute_reply.started":"2025-09-22T18:01:13.645168Z","shell.execute_reply":"2025-09-22T18:01:17.212529Z"}},"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cublas-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cublas-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cublas-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n\u001b[0mИспользуется устройство: cuda\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"DATA_PATH = \"/kaggle/input/avito-task-segment/train.parquet\"\nSAMPLE_SIZE = 320000 \nMAX_LEN = 128 \n\nprint(f\"Загружаем parquet-файл '{DATA_PATH}'...\")\nfull_df = pd.read_parquet(DATA_PATH)\n\nprint(f\"Берем случайную выборку из {SAMPLE_SIZE} строк...\")\ndf = full_df.sample(n=SAMPLE_SIZE, random_state=42)\n\ndef create_bio_labels_pd(row):\n    text_no_spaces = row[\"sentence_without_spaces\"]\n    space_positions = set(pos - 1 for pos in row[\"true_positions\"])\n    labels = [1 if i in space_positions else 0 for i in range(len(text_no_spaces))]\n    return text_no_spaces, labels\n\nprint(\"Создаем данные (текст, метки на символ)...\")\nprocessed_data = [create_bio_labels_pd(row) for index, row in tqdm(df.iterrows(), total=len(df))]\ntexts = [item[0] for item in processed_data]\nlabels = [item[1] for item in processed_data]\n\nall_text = \"\".join(texts)\nchars = sorted(list(set(all_text)))\nchar_to_id = {c: i + 2 for i, c in enumerate(chars)}\nchar_to_id[\"<PAD>\"] = 0\nchar_to_id[\"<UNK>\"] = 1\nVOCAB_SIZE = len(char_to_id)\nprint(f\"Размер словаря символов: {VOCAB_SIZE}\")\n\nprint(f\"Преобразуем тексты в последовательности ID и обрезаем до {MAX_LEN} символов...\")\nX = [[char_to_id.get(c, char_to_id[\"<UNK>\"]) for c in text] for text in texts]\ny = [[label for label in label_seq] for label_seq in labels]\n\nX_padded = np.array([seq[:MAX_LEN] + [char_to_id[\"<PAD>\"]] * (MAX_LEN - len(seq)) for seq in X])\ny_padded = np.array([seq[:MAX_LEN] + [-100] * (MAX_LEN - len(seq)) for seq in y])\n\nX_train, X_val, y_train, y_val = train_test_split(X_padded, y_padded, test_size=0.15, random_state=42)\n\nclass WordSegDataset(Dataset):\n    def __init__(self, texts, labels):\n        self.texts = torch.tensor(texts, dtype=torch.long)\n        self.labels = torch.tensor(labels, dtype=torch.long)\n    def __len__(self):\n        return len(self.labels)\n    def __getitem__(self, idx):\n        return self.texts[idx], self.labels[idx]\n\ntrain_dataset = WordSegDataset(X_train, y_train)\nval_dataset = WordSegDataset(X_val, y_val)\n\nBATCH_SIZE = 256\ntrain_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n\nprint(f\"Размеры выборок: train={len(train_dataset)}, val={len(val_dataset)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T18:02:43.054500Z","iopub.execute_input":"2025-09-22T18:02:43.054842Z","iopub.status.idle":"2025-09-22T18:03:14.809275Z","shell.execute_reply.started":"2025-09-22T18:02:43.054818Z","shell.execute_reply":"2025-09-22T18:03:14.808411Z"}},"outputs":[{"name":"stdout","text":"Загружаем parquet-файл '/kaggle/input/avito-task-segment/train.parquet'...\nБерем случайную выборку из 320000 строк...\nСоздаем данные (текст, метки на символ)...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/320000 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0013d80d84904bdb99aa1d37983bf40c"}},"metadata":{}},{"name":"stdout","text":"Размер словаря символов: 675\nПреобразуем тексты в последовательности ID и обрезаем до 128 символов...\nРазмеры выборок: train=272000, val=48000\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"EMBEDDING_DIM = 64\nLSTM_UNITS = 128\nEPOCHS = 3\nLEARNING_RATE = 0.001\n\nclass BiLSTM_CRF(nn.Module):\n    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_labels):\n        super(BiLSTM_CRF, self).__init__()\n        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=1, bidirectional=True, batch_first=True)\n        self.hidden2tag = nn.Linear(hidden_dim * 2, num_labels)\n        self.crf = CRF(num_labels, batch_first=True)\n\n    def forward(self, x):\n        mask = (x != 0).bool()\n        embeds = self.embedding(x)\n        lstm_out, _ = self.lstm(embeds)\n        emissions = self.hidden2tag(lstm_out)\n        return emissions, mask\n\n    def loss(self, x, tags):\n        emissions, mask = self.forward(x)\n        active_tags = torch.where(mask, tags, torch.tensor(0).type_as(tags))\n        return -self.crf(emissions, active_tags, mask=mask, reduction='mean')\n    \n    def predict(self, x):\n        emissions, mask = self.forward(x)\n        return self.crf.decode(emissions, mask=mask)\n\nmodel_bilstm_crf = BiLSTM_CRF(VOCAB_SIZE, EMBEDDING_DIM, LSTM_UNITS, 2).to(device)\noptimizer = torch.optim.Adam(model_bilstm_crf.parameters(), lr=LEARNING_RATE)\n\nprint(\"Начинаем обучение модели Bi-LSTM+CRF на PyTorch...\")\nfor epoch in range(EPOCHS):\n    model_bilstm_crf.train()\n    train_loss = 0\n    for texts, labels in tqdm(train_loader, desc=f\"Эпоха {epoch+1}/{EPOCHS}\"):\n        texts, labels = texts.to(device), labels.to(device)\n        \n        mask = (labels != -100)\n        if not mask.any(): continue\n\n        optimizer.zero_grad()\n        loss = model_bilstm_crf.loss(texts, labels)\n        loss.backward()\n        optimizer.step()\n        train_loss += loss.item()\n    \n    model_bilstm_crf.eval()\n    val_loss = 0\n    with torch.no_grad():\n        for texts, labels in val_loader:\n            texts, labels = texts.to(device), labels.to(device)\n            mask = (labels != -100)\n            if not mask.any(): continue\n            loss = model_bilstm_crf.loss(texts, labels)\n            val_loss += loss.item()\n    \n    print(f\"Эпоха {epoch+1}: Train Loss: {train_loss/len(train_loader):.4f}, Val Loss: {val_loss/len(val_loader):.4f}\")\n\nprint(\"\\nОбучение завершено.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T18:04:00.078510Z","iopub.execute_input":"2025-09-22T18:04:00.079128Z","iopub.status.idle":"2025-09-22T18:12:31.195114Z","shell.execute_reply.started":"2025-09-22T18:04:00.079102Z","shell.execute_reply":"2025-09-22T18:12:31.194497Z"}},"outputs":[{"name":"stdout","text":"Начинаем обучение модели Bi-LSTM+CRF на PyTorch...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Эпоха 1/3:   0%|          | 0/1063 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fffd7a5a7dd64842a66f52eca68767a5"}},"metadata":{}},{"name":"stdout","text":"Эпоха 1: Train Loss: 5.4869, Val Loss: 3.3527\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Эпоха 2/3:   0%|          | 0/1063 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ee19817fe5ec435eb96d6e37a9c14c55"}},"metadata":{}},{"name":"stdout","text":"Эпоха 2: Train Loss: 2.8883, Val Loss: 2.7102\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Эпоха 3/3:   0%|          | 0/1063 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"86ec059031434ead8ad281c8b16f1173"}},"metadata":{}},{"name":"stdout","text":"Эпоха 3: Train Loss: 2.4602, Val Loss: 2.4700\n\nОбучение завершено.\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"def predict_spaces(text: str, model, char_to_id_map, max_len, device):\n    if not text or not isinstance(text, str):\n        return []\n\n    model.eval()\n    \n    token_ids = [char_to_id_map.get(c, char_to_id_map[\"<UNK>\"]) for c in text[:max_len]]\n    \n    input_tensor = torch.tensor([token_ids], dtype=torch.long).to(device)\n    \n    with torch.no_grad():\n        predicted_labels_list = model.predict(input_tensor)\n        \n    if not predicted_labels_list or not predicted_labels_list[0]:\n        return []\n    \n    predicted_labels = predicted_labels_list[0] # Предсказания для первой (и единственной) строки\n\n    positions = []\n    for i in range(len(text[:max_len])):\n        if i < len(predicted_labels) and predicted_labels[i] == 1: # 1 - метка \"нужен пробел\"\n            positions.append(i + 1) # Позиция - это индекс СЛЕДУЮЩЕГО символа\n            \n    return positions\n\nexample_row = df.iloc[10] # iloc для pandas\nsample_text = example_row['sentence_without_spaces']\ntrue_pos = example_row['true_positions']\n\npredicted_pos = predict_spaces(sample_text, model_bilstm_crf, char_to_id, MAX_LEN, device)\n\nprint(f\"Пример текста: {sample_text}\")\nprint(f\"Истинные позиции: {true_pos}\")\nprint(f\"Предсказанные позиции: {predicted_pos}\")\nprint(\"\\nЯчейка 4: Функция инференса готова.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T18:12:43.273028Z","iopub.execute_input":"2025-09-22T18:12:43.273314Z","iopub.status.idle":"2025-09-22T18:12:43.287333Z","shell.execute_reply.started":"2025-09-22T18:12:43.273292Z","shell.execute_reply":"2025-09-22T18:12:43.286755Z"}},"outputs":[{"name":"stdout","text":"Пример текста: нимолоденькиедевушки,ниихмамы...\nИстинные позиции: [ 2 13 21 23 25]\nПредсказанные позиции: [2, 13, 21, 25]\n\nЯчейка 4: Функция инференса готова.\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"TEST_PATH = \"/kaggle/input/avito-task-segment/test.parquet\"\ntest_df_eval = pd.read_parquet(TEST_PATH)\n\nprint(\"Начинаем предсказание на тестовой выборке для оценки F1...\")\nsentences_to_eval = test_df_eval[\"sentence_without_spaces\"].tolist()\ntrue_positions_eval = test_df_eval[\"true_positions\"].tolist()\n\npredicted_positions_eval = [\n    predict_spaces(s, model_bilstm_crf, char_to_id, MAX_LEN, device)\n    for s in tqdm(sentences_to_eval, desc=\"Оценка модели\")\n]\n\ndef calculate_f1_corrected(predicted: list, true: list) -> float:\n    if len(predicted) == 0 and len(true) == 0: return 1.0\n    pred_set = set(predicted)\n    true_set = set(true)\n    tp = len(pred_set.intersection(true_set))\n    precision = tp / len(pred_set) if pred_set else 0.0\n    recall = tp / len(true_set) if true_set else 0.0\n    if precision + recall == 0: return 0.0\n    f1 = 2 * (precision * recall) / (precision + recall)\n    return f1\n\nf1_scores = [\n    calculate_f1_corrected(pred, true)\n    for pred, true in zip(predicted_positions_eval, true_positions_eval)\n]\n\nmean_f1 = sum(f1_scores) / len(f1_scores) if f1_scores else 0.0\nprint(\"-\" * 50)\nprint(f\"ИТОГОВЫЙ РЕЗУЛЬТАТ (Bi-LSTM+CRF):\")\nprint(f\"Средний F1-score на тестовой выборке: {mean_f1:.4f}\")\nprint(\"-\" * 50)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T18:18:35.264612Z","iopub.execute_input":"2025-09-22T18:18:35.265286Z","iopub.status.idle":"2025-09-22T18:21:20.083128Z","shell.execute_reply.started":"2025-09-22T18:18:35.265262Z","shell.execute_reply":"2025-09-22T18:21:20.082407Z"}},"outputs":[{"name":"stdout","text":"Начинаем предсказание на тестовой выборке для оценки F1...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Оценка модели:   0%|          | 0/37500 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"143abb62a4e142789ceba98ad9670bae"}},"metadata":{}},{"name":"stdout","text":"--------------------------------------------------\nИТОГОВЫЙ РЕЗУЛЬТАТ (Bi-LSTM+CRF):\nСредний F1-score на тестовой выборке: 0.8734\n--------------------------------------------------\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"SUBMISSION_TEMPLATE_PATH = \"/kaggle/input/avito-task-segment/submission.parquet\"\nsubmission_df = pd.read_parquet(SUBMISSION_TEMPLATE_PATH)\n\npredicted_positions_for_submission = []\n\nprint(\"Начинаем генерацию предсказаний для финального сабмита...\")\nfor text in tqdm(submission_df['text_no_spaces'], desc=\"Генерация сабмита\"):\n    positions = predict_spaces(text, model_bilstm_crf, char_to_id, MAX_LEN, device)\n    \n    positions_str = str(sorted(positions))\n    predicted_positions_for_submission.append(positions_str)\n\nsubmission_df['predicted_positions'] = predicted_positions_for_submission\nfinal_submission_df = submission_df[['id', 'predicted_positions']]\nfinal_submission_df.to_csv('submission.csv', index=False)\n\nprint(\"\\nФайл submission.csv успешно создан и готов к отправке!\")\nprint(\"Пример содержимого:\")\nprint(final_submission_df.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-22T18:21:52.055261Z","iopub.execute_input":"2025-09-22T18:21:52.055556Z","iopub.status.idle":"2025-09-22T18:21:55.048172Z","shell.execute_reply.started":"2025-09-22T18:21:52.055534Z","shell.execute_reply":"2025-09-22T18:21:55.047544Z"}},"outputs":[{"name":"stdout","text":"Начинаем генерацию предсказаний для финального сабмита...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Генерация сабмита:   0%|          | 0/1005 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"259181ee65814c3599c508d328bffe16"}},"metadata":{}},{"name":"stdout","text":"\nФайл submission.csv успешно создан и готов к отправке!\nПример содержимого:\n   id      predicted_positions\n0   0              [5, 10, 12]\n1   1                   [6, 7]\n2   2  [4, 12, 13, 20, 21, 29]\n3   3          [5, 10, 18, 26]\n4   4              [5, 10, 15]\n","output_type":"stream"}],"execution_count":23}]}