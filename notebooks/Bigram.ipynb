{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2fd4ea6-8179-4e26-a0d2-5dc1eccf3beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Найденные файлы: ['../data/proccesed_data/item_info_train.parquet', '../data/proccesed_data/item_info.parquet', '../data/proccesed_data/pesni.parquet', '../data/proccesed_data/processed_corpus.parquet']\n",
      "\n",
      "Составляем план для загрузки 10% из каждого файла...\n",
      "  - Файл 'item_info_train.parquet': всего строк 16276308, берем 1627630\n",
      "  - Файл 'item_info.parquet': всего строк 5810022, берем 581002\n",
      "  - Файл 'pesni.parquet': всего строк 4940902, берем 494090\n",
      "  - Файл 'processed_corpus.parquet': всего строк 9321, берем 932\n",
      "\n",
      "Всего строк в сэмпле: 2703654\n",
      "Обучающая выборка: 2433288\n",
      "Тестовая выборка: 270366\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import polars as pl\n",
    "import glob\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import Counter, defaultdict\n",
    "import math\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "pl.Config.set_fmt_str_lengths(120)\n",
    "\n",
    "DATA_PATH = '../data/proccesed_data/'\n",
    "all_parquet_files = glob.glob(f\"{DATA_PATH}*.parquet\")\n",
    "\n",
    "if not all_parquet_files:\n",
    "    raise FileNotFoundError(f\"В папке {DATA_PATH} не найдено parquet-файлов.\")\n",
    "\n",
    "print(f\"Найденные файлы: {all_parquet_files}\")\n",
    "\n",
    "SAMPLE_FRACTION = 0.1\n",
    "lazy_frames = []\n",
    "print(f\"\\nСоставляем план для загрузки {SAMPLE_FRACTION*100:.0f}% из каждого файла...\")\n",
    "\n",
    "for file in all_parquet_files:\n",
    "    lf = pl.scan_parquet(file)\n",
    "    total_rows = lf.select(pl.len()).collect().item()\n",
    "    sample_size = int(total_rows * SAMPLE_FRACTION)\n",
    "    \n",
    "    sampled_lf = lf.with_columns(\n",
    "        pl.lit(pl.arange(0, total_rows, eager=True).shuffle(seed=RANDOM_SEED)).alias(\"random_index\")\n",
    "    ).sort(\"random_index\").head(sample_size).drop(\"random_index\")\n",
    "    lazy_frames.append(sampled_lf)\n",
    "    print(f\"  - Файл '{file.split('/')[-1]}': всего строк {total_rows}, берем {sample_size}\")\n",
    "\n",
    "def get_space_positions(sentence: str) -> list:\n",
    "    if not isinstance(sentence, str) or not sentence:\n",
    "        return []\n",
    "    words = sentence.split(' ')\n",
    "    positions = []\n",
    "    current_pos = 0\n",
    "    for i, word in enumerate(words):\n",
    "        current_pos += len(word)\n",
    "        if i < len(words) - 1:\n",
    "            positions.append(current_pos)\n",
    "    return positions\n",
    "\n",
    "df = pl.concat(lazy_frames).collect()\n",
    "df = df.with_columns(\n",
    "    pl.col(\"sentence_with_spaces\").map_elements(get_space_positions, return_dtype=pl.List(pl.Int64)).alias(\"true_positions\")\n",
    ")\n",
    "df = df.sample(fraction=1, shuffle=True, seed=RANDOM_SEED)\n",
    "\n",
    "train_fraction = 0.9\n",
    "train_size = int(train_fraction * len(df))\n",
    "train_df = df.slice(0, train_size)\n",
    "test_df = df.slice(train_size)\n",
    "\n",
    "print(f\"\\nВсего строк в сэмпле: {len(df)}\")\n",
    "print(f\"Обучающая выборка: {len(train_df)}\")\n",
    "print(f\"Тестовая выборка: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ab9ff33-96e4-482d-880a-82fece8de502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Строим биграммную языковую модель...\n",
      "Модель создана. Уникальных слов: 1919082, биграмм: 7530915, макс. длина слова: 50\n"
     ]
    }
   ],
   "source": [
    "print(\"Строим биграммную языковую модель...\")\n",
    "\n",
    "all_words_series = train_df.select(pl.col(\"sentence_with_spaces\").str.split(by=\" \")).explode(\"sentence_with_spaces\")\n",
    "unigram_counts = Counter(all_words_series[\"sentence_with_spaces\"].to_list())\n",
    "total_words = sum(unigram_counts.values())\n",
    "\n",
    "bigram_counts = Counter()\n",
    "sentences = train_df[\"sentence_with_spaces\"].to_list()\n",
    "for sentence in sentences:\n",
    "    words = ['<s>'] + sentence.split(' ') + ['</s>']\n",
    "    for i in range(len(words) - 1):\n",
    "        bigram_counts[(words[i], words[i+1])] += 1\n",
    "\n",
    "log_unigram_probs = {word: math.log(count / total_words) for word, count in unigram_counts.items()}\n",
    "log_bigram_probs = defaultdict(lambda: -math.inf)\n",
    "for (w1, w2), count in bigram_counts.items():\n",
    "    log_bigram_probs[(w1, w2)] = math.log(count / unigram_counts.get(w1, 1))\n",
    "\n",
    "start_word_counts = Counter(word for (prev_word, word), count in bigram_counts.items() if prev_word == '<s>')\n",
    "total_starts = sum(start_word_counts.values())\n",
    "log_start_probs = {word: math.log(count / total_starts) for word, count in start_word_counts.items()}\n",
    "\n",
    "MAX_WORD_LEN = min(all_words_series.select(pl.col(\"sentence_with_spaces\").str.len_chars().max()).item(), 50)\n",
    "\n",
    "language_model = {\n",
    "    \"unigrams\": log_unigram_probs,\n",
    "    \"bigrams\": log_bigram_probs,\n",
    "    \"starts\": log_start_probs,\n",
    "    \"max_len\": MAX_WORD_LEN\n",
    "}\n",
    "print(f\"Модель создана. Уникальных слов: {len(unigram_counts)}, биграмм: {len(bigram_counts)}, макс. длина слова: {MAX_WORD_LEN}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19081672-832d-4adf-9c9f-296446bf8d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_viterbi_bigram(text: str, model: dict) -> list:\n",
    "    n = len(text)\n",
    "    log_unigram_probs = model['unigrams']\n",
    "    log_bigram_probs = model['bigrams']\n",
    "    log_start_probs = model['starts']\n",
    "    max_word_len = model['max_len']\n",
    "    \n",
    "    dp = [defaultdict(lambda: (-math.inf, None)) for _ in range(n + 1)]\n",
    "\n",
    "    for i in range(1, min(n + 1, max_word_len + 1)):\n",
    "        word = text[:i]\n",
    "        if word in log_unigram_probs:\n",
    "            prob = log_start_probs.get(word, log_unigram_probs[word] - math.log(10))\n",
    "            dp[i][word] = (prob, \"<s>\")\n",
    "\n",
    "    for i in range(1, n + 1):\n",
    "        for j in range(max(0, i - max_word_len), i):\n",
    "            current_word = text[j:i]\n",
    "            if current_word in log_unigram_probs:\n",
    "                if not dp[j]: continue\n",
    "                for prev_word, (prev_prob, _) in dp[j].items():\n",
    "                    transition_prob = log_bigram_probs.get(\n",
    "                        (prev_word, current_word), \n",
    "                        log_unigram_probs[current_word] - math.log(1000)\n",
    "                    )\n",
    "                    new_prob = prev_prob + transition_prob\n",
    "                    if new_prob > dp[i][current_word][0]:\n",
    "                        dp[i][current_word] = (new_prob, prev_word)\n",
    "    \n",
    "    if not dp[n]: return []\n",
    "    \n",
    "    best_last_word = max(dp[n].items(), key=lambda item: item[1][0])[0]\n",
    "    \n",
    "    words = []\n",
    "    current_word = best_last_word\n",
    "    i = n\n",
    "    while current_word != \"<s>\":\n",
    "        words.append(current_word)\n",
    "        prev_word = dp[i][current_word][1]\n",
    "        i -= len(current_word)\n",
    "        current_word = prev_word\n",
    "    words.reverse()\n",
    "\n",
    "    positions = []\n",
    "    current_pos = 0\n",
    "    for i, word in enumerate(words):\n",
    "        current_pos += len(word)\n",
    "        if i < len(words) - 1:\n",
    "            positions.append(current_pos)\n",
    "    return positions\n",
    "\n",
    "def calculate_f1_corrected(predicted: list, true: list) -> float:\n",
    "    if not predicted and not true: return 1.0\n",
    "    pred_set = set(predicted)\n",
    "    true_set = set(true)\n",
    "    tp = len(pred_set.intersection(true_set))\n",
    "    precision = tp / len(pred_set) if pred_set else 0.0\n",
    "    recall = tp / len(true_set) if true_set else 0.0\n",
    "    if precision + recall == 0: return 0.0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall)\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b517e49f-9822-4119-afb8-329604ee1c71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9512298dfe5043b68e09b0306d3f86fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Предсказание (Биграммы):   0%|          | 0/270366 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c4af95230144f4d948ea56f3634372d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Вычисление F1:   0%|          | 0/270366 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "ИТОГОВЫЙ РЕЗУЛЬТАТ (БИГРАММНАЯ МОДЕЛЬ):\n",
      "Средний F1-score на тестовой выборке: 0.8983\n",
      "--------------------------------------------------\n",
      "\n",
      "Примеры с низким F1-score:\n",
      "shape: (5, 6)\n",
      "┌──────────┬───────────────────┬───────────────────┬────────────────┬───────────────────┬──────────┐\n",
      "│ id       ┆ sentence_with_spa ┆ sentence_without_ ┆ true_positions ┆ predicted_positio ┆ f1_score │\n",
      "│ ---      ┆ ces               ┆ spaces            ┆ ---            ┆ ns                ┆ ---      │\n",
      "│ i64      ┆ ---               ┆ ---               ┆ list[i64]      ┆ ---               ┆ f64      │\n",
      "│          ┆ str               ┆ str               ┆                ┆ list[i64]         ┆          │\n",
      "╞══════════╪═══════════════════╪═══════════════════╪════════════════╪═══════════════════╪══════════╡\n",
      "│ 4609223  ┆ Вторичка.         ┆ Вторичка.         ┆ []             ┆ [1, 3, 6]         ┆ 0.0      │\n",
      "│ 13343528 ┆ В наличии.        ┆ Вналичии.         ┆ [1]            ┆ []                ┆ 0.0      │\n",
      "│ 8071711  ┆ _________________ ┆ _________________ ┆ []             ┆ [2, 4, … 50]      ┆ 0.0      │\n",
      "│          ┆ _________________ ┆ _________________ ┆                ┆                   ┆          │\n",
      "│          ┆ _________________ ┆ _________________ ┆                ┆                   ┆          │\n",
      "│          ┆ _                 ┆ _                 ┆                ┆                   ┆          │\n",
      "│ 14054611 ┆ 500 р.            ┆ 500р.             ┆ [3]            ┆ []                ┆ 0.0      │\n",
      "│ 3569019  ┆ Ищу работу        ┆ Ищуработу         ┆ [3]            ┆ []                ┆ 0.0      │\n",
      "└──────────┴───────────────────┴───────────────────┴────────────────┴───────────────────┴──────────┘\n",
      "\n",
      "Примеры с высоким F1-score:\n",
      "shape: (5, 6)\n",
      "┌──────────┬───────────────────┬───────────────────┬────────────────┬───────────────────┬──────────┐\n",
      "│ id       ┆ sentence_with_spa ┆ sentence_without_ ┆ true_positions ┆ predicted_positio ┆ f1_score │\n",
      "│ ---      ┆ ces               ┆ spaces            ┆ ---            ┆ ns                ┆ ---      │\n",
      "│ i64      ┆ ---               ┆ ---               ┆ list[i64]      ┆ ---               ┆ f64      │\n",
      "│          ┆ str               ┆ str               ┆                ┆ list[i64]         ┆          │\n",
      "╞══════════╪═══════════════════╪═══════════════════╪════════════════╪═══════════════════╪══════════╡\n",
      "│ 11810066 ┆ Диски R15 для     ┆ ДискиR15длявнедор ┆ [5, 8, 11]     ┆ [5, 8, 11]        ┆ 1.0      │\n",
      "│          ┆ внедорожников.    ┆ ожников.          ┆                ┆                   ┆          │\n",
      "│ 10450169 ┆ Все инструменты   ┆ Всеинструментынов ┆ [3, 14, … 52]  ┆ [3, 14, … 52]     ┆ 1.0      │\n",
      "│          ┆ новые, с          ┆ ые,сдокументамииг ┆                ┆                   ┆          │\n",
      "│          ┆ документами и     ┆ арантией,срокомот ┆                ┆                   ┆          │\n",
      "│          ┆ гарантией, сроком ┆ 1года.            ┆                ┆                   ┆          │\n",
      "│          ┆ от 1 года.        ┆                   ┆                ┆                   ┆          │\n",
      "│ 8750524  ┆ Доставка по СПб   ┆ ДоставкапоСПб     ┆ [8, 10, … 25]  ┆ [8, 10, … 25]     ┆ 1.0      │\n",
      "│          ┆ Отправляем в      ┆ Отправляемврегион ┆                ┆                   ┆          │\n",
      "│          ┆ регионы.          ┆ ы.                ┆                ┆                   ┆          │\n",
      "│ 9229936  ┆ Натуральная кожа. ┆ Натуральнаякожа.  ┆ [11]           ┆ [11]              ┆ 1.0      │\n",
      "│ 14686419 ┆ СРОЧНО            ┆ СРОЧНО            ┆ []             ┆ []                ┆ 1.0      │\n",
      "└──────────┴───────────────────┴───────────────────┴────────────────┴───────────────────┴──────────┘\n"
     ]
    }
   ],
   "source": [
    "sentences_to_process = test_df[\"sentence_without_spaces\"].to_list()\n",
    "\n",
    "predicted_positions_list = [\n",
    "    segment_viterbi_bigram(s, language_model) \n",
    "    for s in tqdm(sentences_to_process, desc=\"Предсказание (Биграммы)\")\n",
    "]\n",
    "\n",
    "results_df = test_df.with_columns(\n",
    "    pl.Series(\"predicted_positions\", predicted_positions_list, dtype=pl.List(pl.Int64))\n",
    ")\n",
    "\n",
    "f1_scores = [\n",
    "    calculate_f1_corrected(row[\"predicted_positions\"], row[\"true_positions\"])\n",
    "    for row in tqdm(results_df.select([\"predicted_positions\", \"true_positions\"]).iter_rows(named=True), \n",
    "                    desc=\"Вычисление F1\", total=len(results_df))\n",
    "]\n",
    "\n",
    "results_df = results_df.with_columns(\n",
    "    pl.Series(\"f1_score\", f1_scores, dtype=pl.Float64)\n",
    ")\n",
    "\n",
    "mean_f1 = results_df['f1_score'].mean()\n",
    "print(\"-\" * 50)\n",
    "print(f\"ИТОГОВЫЙ РЕЗУЛЬТАТ (БИГРАММНАЯ МОДЕЛЬ):\")\n",
    "print(f\"Средний F1-score на тестовой выборке: {mean_f1:.4f}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "print(\"\\nПримеры с низким F1-score:\")\n",
    "print(results_df.sort(\"f1_score\").head(5))\n",
    "\n",
    "print(\"\\nПримеры с высоким F1-score:\")\n",
    "print(results_df.sort(\"f1_score\", descending=True).head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c42049ed-dea4-4aef-a16a-7b546a9ba78c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Перестраиваем финальную биграммную модель на всех доступных данных...\n",
      "Финальная модель готова.\n",
      "\n",
      "Тестовый файл успешно загружен вручную. Количество строк: 1005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Генерация сабмита: 100%|███████████████████| 1005/1005 [00:01<00:00, 784.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Файл submission.csv успешно создан и готов к отправке!\n",
      "Пример содержимого:\n",
      "   id                 text_no_spaces  predicted_positions\n",
      "0   0                куплюайфон14про                   []\n",
      "1   1             ищудомвПодмосковье            [3, 6, 7]\n",
      "2   2  сдаюквартирусмебельюитехникой  [4, 12, 13, 20, 21]\n",
      "3   3     новыйдивандоставканедорого      [5, 10, 18, 20]\n",
      "4   4                отдамдаромкошку              [5, 10]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from collections import Counter, defaultdict\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(\"Перестраиваем финальную биграммную модель на всех доступных данных...\")\n",
    "\n",
    "final_all_words_series = df.select(pl.col(\"sentence_with_spaces\").str.split(by=\" \")).explode(\"sentence_with_spaces\")\n",
    "final_unigram_counts = Counter(final_all_words_series[\"sentence_with_spaces\"].to_list())\n",
    "final_total_words = sum(final_unigram_counts.values())\n",
    "\n",
    "final_bigram_counts = Counter()\n",
    "for sentence in df[\"sentence_with_spaces\"].to_list():\n",
    "    words = ['<s>'] + sentence.split(' ') + ['</s>']\n",
    "    for i in range(len(words) - 1):\n",
    "        final_bigram_counts[(words[i], words[i+1])] += 1\n",
    "\n",
    "final_log_unigram_probs = {word: math.log(count / final_total_words) for word, count in final_unigram_counts.items()}\n",
    "final_log_bigram_probs = defaultdict(lambda: -math.inf)\n",
    "for (w1, w2), count in final_bigram_counts.items():\n",
    "    final_log_bigram_probs[(w1, w2)] = math.log(count / final_unigram_counts.get(w1, 1))\n",
    "\n",
    "final_start_word_counts = Counter(word for (prev_word, word), count in final_bigram_counts.items() if prev_word == '<s>')\n",
    "final_total_starts = sum(final_start_word_counts.values())\n",
    "final_log_start_probs = {word: math.log(count / final_total_starts) for word, count in final_start_word_counts.items()}\n",
    "\n",
    "final_max_word_len = min(final_all_words_series.select(pl.col(\"sentence_with_spaces\").str.len_chars().max()).item(), 50)\n",
    "\n",
    "final_language_model = {\n",
    "    \"unigrams\": final_log_unigram_probs,\n",
    "    \"bigrams\": final_log_bigram_probs,\n",
    "    \"starts\": final_log_start_probs,\n",
    "    \"max_len\": final_max_word_len,\n",
    "    \"total_words\": final_total_words\n",
    "}\n",
    "print(\"Финальная модель готова.\")\n",
    "\n",
    "def segment_viterbi_robust(text: str, model: dict) -> list:\n",
    "    n = len(text)\n",
    "    log_unigram_probs = model['unigrams']\n",
    "    log_bigram_probs = model['bigrams']\n",
    "    log_start_probs = model['starts']\n",
    "    max_word_len = model['max_len']\n",
    "    total_words = model['total_words']\n",
    "\n",
    "    dp = [defaultdict(lambda: (-math.inf, None)) for _ in range(n + 1)]\n",
    "\n",
    "    for i in range(1, min(n + 1, max_word_len + 1)):\n",
    "        word = text[:i]\n",
    "        log_prob_word = log_unigram_probs.get(word)\n",
    "        if log_prob_word is None:\n",
    "            log_prob_word = -math.log(total_words * 10**len(word))\n",
    "\n",
    "        prob = log_start_probs.get(word, log_prob_word)\n",
    "        dp[i][word] = (prob, \"<s>\")\n",
    "\n",
    "    for i in range(1, n + 1):\n",
    "        for j in range(max(0, i - max_word_len), i):\n",
    "            current_word = text[j:i]\n",
    "            \n",
    "            log_prob_current = log_unigram_probs.get(current_word)\n",
    "            if log_prob_current is None:\n",
    "                log_prob_current = -math.log(total_words * 10**len(current_word))\n",
    "\n",
    "            if not dp[j]: continue\n",
    "            \n",
    "            for prev_word, (prev_prob, _) in dp[j].items():\n",
    "                transition_prob = log_bigram_probs.get(\n",
    "                    (prev_word, current_word), \n",
    "                    log_prob_current - math.log(1000) # Штраф за отсутствие биграммы\n",
    "                )\n",
    "                new_prob = prev_prob + transition_prob\n",
    "                if new_prob > dp[i][current_word][0]:\n",
    "                    dp[i][current_word] = (new_prob, prev_word)\n",
    "    \n",
    "    if not dp[n]: return []\n",
    "    \n",
    "    best_last_word = max(dp[n].items(), key=lambda item: item[1][0])[0]\n",
    "    \n",
    "    words = []\n",
    "    current_word = best_last_word\n",
    "    i = n\n",
    "    while current_word != \"<s>\":\n",
    "        words.append(current_word)\n",
    "        prev_word = dp[i][current_word][1]\n",
    "        i -= len(current_word)\n",
    "        current_word = prev_word\n",
    "    words.reverse()\n",
    "\n",
    "    positions = []\n",
    "    current_pos = 0\n",
    "    for i, word in enumerate(words):\n",
    "        current_pos += len(word)\n",
    "        if i < len(words) - 1:\n",
    "            positions.append(current_pos)\n",
    "    return positions\n",
    "\n",
    "\n",
    "TEST_FILE_PATH = '../data/dataset_1937770_3.txt'\n",
    "test_data_rows = []\n",
    "try:\n",
    "    with open(TEST_FILE_PATH, 'r', encoding='utf-8') as f:\n",
    "        # Пропускаем заголовок\n",
    "        next(f) \n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            # Разделяем строку только по первой запятой\n",
    "            parts = line.split(',', 1)\n",
    "            if len(parts) == 2:\n",
    "                row_id, text = parts\n",
    "                test_data_rows.append({'id': int(row_id), 'text_no_spaces': text})\n",
    "\n",
    "    task_data_df = pd.DataFrame(test_data_rows)\n",
    "    print(f\"\\nТестовый файл успешно загружен вручную. Количество строк: {len(task_data_df)}\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Ошибка: тестовый файл '{TEST_FILE_PATH}' не найден.\")\n",
    "    task_data_df = pd.DataFrame(columns=['id', 'text_no_spaces'])\n",
    "\n",
    "predicted_positions_for_submission = []\n",
    "for text in tqdm(task_data_df['text_no_spaces'], desc=\"Генерация сабмита\"):\n",
    "    if pd.isna(text):\n",
    "        predicted_positions_for_submission.append(\"[]\")\n",
    "        continue\n",
    "    \n",
    "    positions = segment_viterbi_robust(str(text), final_language_model)\n",
    "    positions_str = str(sorted(positions))\n",
    "    predicted_positions_for_submission.append(positions_str)\n",
    "\n",
    "submission_df = task_data_df.copy()\n",
    "submission_df['predicted_positions'] = predicted_positions_for_submission\n",
    "submission_df.to_csv('submission.csv', index=False)\n",
    "\n",
    "print(\"\\nФайл submission.csv успешно создан и готов к отправке!\")\n",
    "print(\"Пример содержимого:\")\n",
    "print(submission_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e1d8282-dc47-447a-a267-f1e6b0e4ddec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Файл submission.csv успешно создан и готов к отправке!\n",
      "Пример содержимого:\n",
      "   id  predicted_positions\n",
      "0   0                   []\n",
      "1   1            [3, 6, 7]\n",
      "2   2  [4, 12, 13, 20, 21]\n",
      "3   3      [5, 10, 18, 20]\n",
      "4   4              [5, 10]\n"
     ]
    }
   ],
   "source": [
    "submission_df = pd.DataFrame({\n",
    "    'id': task_data_df['id'],\n",
    "    'predicted_positions': predicted_positions_for_submission\n",
    "})\n",
    "\n",
    "submission_df.to_csv('submission.csv', index=False)\n",
    "\n",
    "print(\"\\nФайл submission.csv успешно создан и готов к отправке!\")\n",
    "print(\"Пример содержимого:\")\n",
    "print(submission_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0b0971-8c60-4a61-be75-90275a42f53d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (notebook)",
   "language": "python",
   "name": "notebook"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
